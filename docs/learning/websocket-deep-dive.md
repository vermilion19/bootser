# WebSocket 프로젝트가 어려운 이유와 제대로 다루는 법

## 시니어가 "기술 규모가 커진다"고 한 이유

WebSocket은 HTTP와 근본적으로 다르다. HTTP는 요청-응답 후 연결이 끝나지만, WebSocket은 **연결이 계속 살아 있다**. 이 하나의 차이가 모든 복잡성의 근원이다.

---

## 1. 연결 상태 관리 (Stateful)

### 문제

HTTP는 Stateless다. 요청이 오면 아무 서버나 받아서 처리하면 된다. 로드밸런서 뒤에 서버 10대를 두면 자연스럽게 분산된다.

WebSocket은 Stateful이다. 클라이언트 A가 서버 1에 연결하면, 그 연결은 서버 1에 **종속**된다. 서버 2는 A의 존재를 모른다.

```
[HTTP - 단순]
Client → LB → 아무 서버나 → 응답 → 끝

[WebSocket - 복잡]
Client A ←──── 지속 연결 ────→ Server 1  (Server 2는 A를 모름)
Client B ←──── 지속 연결 ────→ Server 2  (Server 1은 B를 모름)
```

### 이게 왜 문제인가

A에게 메시지를 보내야 하는데, A가 어느 서버에 연결되어 있는지 알아야 한다. 서버가 1대면 상관없지만, 운영 환경에서 서버 1대는 말이 안 된다.

```
유저 B가 유저 A에게 메시지 전송:
1. B의 요청이 Server 2에 도착
2. A는 Server 1에 연결되어 있음
3. Server 2 → ??? → Server 1 → A에게 전달

이 "???" 을 해결하는 것이 핵심 난제
```

---

## 2. Scale-out이 근본적으로 어려움

### HTTP 서비스의 Scale-out

```
서버 부하 증가 → 서버 추가 → 로드밸런서가 분산 → 끝
```

### WebSocket 서비스의 Scale-out

```
서버 부하 증가 → 서버 추가 → 그런데...
  - 기존 연결은 이동 안 됨
  - 새 서버는 기존 클라이언트를 모름
  - 서버 간 메시지 라우팅 필요
  - 연결 레지스트리 필요 (누가 어디에 연결되어 있는지)
  - Sticky Session 또는 별도 라우팅 레이어 필요
```

필요해지는 기술 스택:

| 문제 | 해결 기술 |
|------|-----------|
| 서버 간 메시지 전달 | Redis Pub/Sub, Kafka, RabbitMQ |
| 연결 위치 추적 | Redis에 세션 레지스트리 관리 |
| Sticky Session | LB의 IP Hash, Cookie 기반 라우팅 |
| 연결 수 분산 | Consistent Hashing |

이미 여기서 Redis + 메시지 브로커 + 로드밸런서 설정이 필요하다. HTTP 서비스에선 없어도 되는 것들이다.

---

## 3. 연결 수 = 서버 리소스 점유

### HTTP

```
동시 사용자 10만 명 → 실제 동시 요청은 수백~수천 → 서버 몇 대로 처리 가능
(요청 완료 후 리소스 반환)
```

### WebSocket

```
동시 사용자 10만 명 → 10만 개의 TCP 연결 유지 → 서버 리소스 상시 점유
- 파일 디스크립터 10만 개
- 메모리: 연결당 수~수십 KB × 10만 = 수 GB
- 하트비트 트래픽: 10만 × 30초마다 ping/pong
```

고려해야 할 것들:

| 항목 | 설명 |
|------|------|
| OS 튜닝 | `ulimit -n`, `net.core.somaxconn`, `tcp_keepalive_time` |
| JVM 튜닝 | 힙 사이즈, GC 전략 (연결 객체가 장수 객체) |
| 커넥션 제한 | 서버당 최대 연결 수 제한 + graceful rejection |
| 하트비트 | ping/pong 간격, 타임아웃 후 연결 정리 |
| Backpressure | 느린 클라이언트에게 메시지가 쌓이는 문제 |

---

## 4. 연결 끊김 처리

HTTP는 요청 실패하면 다시 요청하면 된다. WebSocket은 연결이 끊기면 **상태가 날아간다**.

### 처리해야 할 시나리오

```
1. 네트워크 순단 (지하철, 엘리베이터)
   → 재연결 후 끊긴 동안의 메시지를 어떻게 받을 것인가?

2. 서버 배포로 인한 연결 종료
   → 10만 연결이 동시에 끊기고 재연결 → Thundering Herd

3. 클라이언트가 그냥 사라짐 (앱 kill, 배터리 방전)
   → 서버가 언제 감지할 것인가? (하트비트 타임아웃)

4. 서버 장애로 연결 종료
   → 다른 서버에 재연결 → 이전 상태 복구 필요
```

### 필요한 구현

```
[메시지 유실 방지]
- 메시지에 시퀀스 번호 부여
- 클라이언트가 마지막 수신 번호 기억
- 재연결 시 "나 N번까지 받았어" → 서버가 N+1부터 재전송
- 이를 위해 메시지 버퍼/저장소 필요 (Redis, DB)

[재연결 전략]
- Exponential Backoff + Jitter (동시 재연결 방지)
- 연결 복구 중 로컬 큐에 메시지 버퍼링
- 재연결 시 인증 토큰 갱신 처리
```

---

## 5. 인증/보안

HTTP는 매 요청에 토큰을 보낸다. 토큰 만료되면 401 응답하면 된다.

WebSocket은 한 번 연결되면 끝이다.

```
1. 최초 연결 시 토큰 검증 (handshake 단계)
2. 연결 중 토큰이 만료되면?
   - 선택지 A: 연결 강제 종료 → 재연결 → 재인증
   - 선택지 B: 연결 유지하면서 토큰 갱신 메시지 교환
3. 권한 변경 시 (탈퇴, 차단 등) 실시간 연결 종료 필요
4. CSRF 방지: WebSocket은 Origin 헤더로 검증
5. Rate Limiting: 연결당 메시지 빈도 제한 (악성 클라이언트 방지)
```

---

## 6. 메시지 순서 보장과 전달 보장

### HTTP

요청 A 보내고 응답 받고, 요청 B 보내고 응답 받는다. 순서가 명확하다.

### WebSocket

양방향으로 동시에 메시지가 날아간다.

```
[순서 문제]
Server → Client: 메시지 A (먼저 발송)
Server → Client: 메시지 B (나중 발송)
Client 수신: B → A (네트워크 경로에 따라 역전 가능? → TCP라 순서 보장되긴 함)

하지만 멀티 서버 환경에서:
Server 1 → Redis Pub/Sub → Server 2 → Client
Server 1 → Redis Pub/Sub → Server 3 → Client (서버 이동 후)
이 경우 순서 보장이 깨질 수 있음
```

**전달 보장 수준 결정:**

| 수준 | 설명 | 구현 복잡도 |
|------|------|------------|
| At-most-once | 보내고 끝, 유실 허용 | 낮음 |
| At-least-once | ACK 없으면 재전송, 중복 가능 | 중간 |
| Exactly-once | 중복 없이 정확히 1회 | 매우 높음 |

채팅이면 At-least-once + 클라이언트 중복 제거가 현실적이다.

---

## 7. 모니터링/디버깅의 어려움

HTTP는 access log에 모든 요청/응답이 남는다. 각 요청이 독립적이라 디버깅이 쉽다.

WebSocket은:

```
- 연결이 언제 맺어지고 언제 끊겼는지
- 연결 중 어떤 메시지가 오갔는지
- 특정 클라이언트의 연결 상태가 지금 어떤지
- 서버별 연결 수 분포는 어떤지
- 메시지 전달 지연은 얼마나 되는지
```

이걸 다 추적하려면 별도의 모니터링 체계가 필요하다.

```
필요한 메트릭:
- 서버별 활성 연결 수
- 초당 메시지 처리량 (인바운드/아웃바운드)
- 메시지 전달 레이턴시 (p50/p95/p99)
- 연결 유지 시간 분포
- 재연결 빈도
- 메시지 유실률
- 서버 간 메시지 라우팅 지연
```

---

## 8. 배포의 복잡성

### HTTP 서비스 배포

```
Rolling Update → 기존 요청 처리 완료 → 새 버전으로 교체 → 끝
```

### WebSocket 서비스 배포

```
서버에 만 개의 연결이 있는 상태에서 배포:
1. 새 연결 수락 중지 (drain)
2. 기존 연결에 "곧 끊긴다" 알림 → 클라이언트가 다른 서버로 재연결 준비
3. 일정 시간 대기 (grace period)
4. 남은 연결 강제 종료
5. 서버 교체
6. 만 개의 클라이언트가 동시에 다른 서버로 재연결 → 부하 분산 필요

이 과정을 Rolling으로 서버 한 대씩 반복
```

---

## 9. 테스트의 어려움

```
HTTP 테스트: 요청 보내고 응답 검증 → 끝

WebSocket 테스트:
- 동시 N천 개 연결 부하 테스트
- 연결 중 네트워크 끊김 시뮬레이션
- 서버 장애 시 재연결 + 메시지 복구 검증
- 멀티 서버 환경에서 메시지 라우팅 검증
- 느린 클라이언트(Slow Consumer) 시뮬레이션
- 메모리 누수 장시간 테스트 (연결 객체 해제 안 되는 케이스)
```

---

## 전체 기술 스택 조감도

"WebSocket 제대로" 하려면 이만큼 필요하다:

```
[클라이언트]
├── WebSocket 클라이언트 라이브러리
├── 재연결 로직 (Exponential Backoff + Jitter)
├── 메시지 시퀀싱 / 중복 제거
├── 로컬 메시지 큐 (연결 끊김 중 버퍼링)
└── 하트비트 처리

[로드밸런서]
├── L7 LB (WebSocket Upgrade 지원)
├── Sticky Session 또는 라우팅 레이어
├── Connection Draining (배포 시)
└── Health Check (WebSocket 엔드포인트)

[WebSocket 서버]
├── 연결 관리 (세션 레지스트리)
├── 인증/인가 (핸드셰이크 + 토큰 갱신)
├── 메시지 라우팅 (로컬 + 원격)
├── 하트비트 / 연결 정리
├── Backpressure 처리
├── Rate Limiting
└── Graceful Shutdown

[메시지 브로커]
├── Redis Pub/Sub (서버 간 메시지 전달)
│   또는 Kafka (메시지 영속성 필요 시)
└── 메시지 버퍼 (재연결 시 재전송용)

[세션 저장소 - Redis]
├── 연결 레지스트리 (userId → serverId)
├── 메시지 시퀀스 관리
└── 재전송 버퍼

[모니터링]
├── 연결 수 / 메시지 처리량 메트릭
├── 메시지 전달 레이턴시
├── 연결 끊김 / 재연결 추적
└── 서버별 연결 분포 대시보드

[인프라]
├── OS 튜닝 (파일 디스크립터, TCP 설정)
├── JVM 튜닝 (GC, 힙)
├── 오토스케일링 (연결 수 기반)
└── 배포 파이프라인 (Connection Draining 포함)
```

---

## 시니어를 만족시키려면

단순히 "WebSocket으로 채팅 만들었어요"로는 부족하다. 위에 나열된 문제 중 최소한 이것들은 **고민하고 구현한 흔적**이 있어야 한다:

### 최소 요구 수준

| # | 항목 | 구체적으로 |
|---|------|-----------|
| 1 | 멀티 서버 메시지 라우팅 | Redis Pub/Sub로 서버 간 메시지 전달 |
| 2 | 세션 레지스트리 | Redis에 userId-serverId 매핑 관리 |
| 3 | 재연결 + 메시지 복구 | 시퀀스 번호 기반 유실 메시지 재전송 |
| 4 | 인증 | 핸드셰이크 시 JWT 검증 + 만료 처리 |
| 5 | Graceful Shutdown | 배포 시 연결 이관 처리 |
| 6 | 모니터링 | 연결 수, 메시지 처리량, 레이턴시 메트릭 |
| 7 | 부하 테스트 | 동시 N천 연결 시나리오 테스트 결과 |

### 차별화 포인트 (이것까지 하면 인정받음)

| # | 항목 | 설명 |
|---|------|------|
| 1 | Backpressure | Slow Consumer 감지 및 메시지 드롭/버퍼링 전략 |
| 2 | 메시지 전달 보장 | At-least-once + 클라이언트 중복 제거 |
| 3 | 연결 수 기반 오토스케일링 | HTTP 서비스와 다른 스케일링 전략 |
| 4 | 장애 시나리오 대응 문서 | 서버 다운, 네트워크 파티션 시 동작 정리 |
| 5 | 성능 벤치마크 | 서버 1대당 최대 연결 수, 메시지 처리량 측정 |

### 핵심 메시지

```
HTTP 서비스: 비즈니스 로직에 집중하면 된다. 인프라는 프레임워크가 해결해준다.
WebSocket 서비스: 비즈니스 로직보다 인프라/통신 레이어에 쏟는 노력이 더 크다.
```

시니어가 "기술 규모가 커진다"고 한 건 이 뜻이다. WebSocket 자체는 어렵지 않지만, **제대로 운영 가능한 수준**으로 만들려면 다뤄야 할 기술이 HTTP 기반 서비스의 몇 배가 된다.